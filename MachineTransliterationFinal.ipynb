{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Skshamim02/Machine_transliteration/blob/main/MachineTransliterationFinal.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tNkodxw05abe",
        "outputId": "de5b054a-35a1-4e68-ee8a-ec01e5130b27"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting fasttext\n",
            "  Downloading fasttext-0.9.2.tar.gz (68 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/68.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.8/68.8 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pybind11>=2.2 (from fasttext)\n",
            "  Using cached pybind11-2.10.4-py3-none-any.whl (222 kB)\n",
            "Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from fasttext) (67.7.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from fasttext) (1.22.4)\n",
            "Building wheels for collected packages: fasttext\n",
            "  Building wheel for fasttext (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fasttext: filename=fasttext-0.9.2-cp310-cp310-linux_x86_64.whl size=4393266 sha256=2c275bbeac97976b20a7f36bbdc4e85285772f8438cd8115d1da1ee899b9cfff\n",
            "  Stored in directory: /root/.cache/pip/wheels/a5/13/75/f811c84a8ab36eedbaef977a6a58a98990e8e0f1967f98f394\n",
            "Successfully built fasttext\n",
            "Installing collected packages: pybind11, fasttext\n",
            "Successfully installed fasttext-0.9.2 pybind11-2.10.4\n"
          ]
        }
      ],
      "source": [
        "pip install fasttext"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lTaMwWO07aMO"
      },
      "outputs": [],
      "source": [
        "import fasttext"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yl3os03SKNNy"
      },
      "source": [
        "The following code loads a pretrained English FastText model from the specified file path using the fasttext library and assigns it to the variable english_model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dGR29JLH7rC2",
        "outputId": "2ba9b5db-a409-46c3-e268-ec20b85f4c6e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
          ]
        }
      ],
      "source": [
        "# Path to the pretrained English FastText model\n",
        "english_model_path = '/content/drive/MyDrive/Colab Notebooks/cc.en.300.bin'\n",
        "\n",
        "# Load the pretrained English FastText model\n",
        "english_model = fasttext.load_model(english_model_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "stiDhwgw777t",
        "outputId": "7e97e4b5-3908-43d3-e5ba-67ca496f1c2c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "300"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "english_model.get_dimension()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xOqkPTce9IAU"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "RvbdrPSi-I4W",
        "outputId": "0230d4f7-f956-46bc-e018-48d6c5b4491c"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-b7a5dac6-426e-4cd8-a4fe-291c4241819c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>unique_identifier</th>\n",
              "      <th>native word</th>\n",
              "      <th>english word</th>\n",
              "      <th>source</th>\n",
              "      <th>score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>mni1</td>\n",
              "      <td>ꯂꯨꯗꯨ</td>\n",
              "      <td>ludu</td>\n",
              "      <td>AK-Freq</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>mni2</td>\n",
              "      <td>ꯑꯣꯛꯁꯥ</td>\n",
              "      <td>oksha</td>\n",
              "      <td>AK-Freq</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>mni3</td>\n",
              "      <td>ꯊꯝꯕꯥꯜ</td>\n",
              "      <td>thambal</td>\n",
              "      <td>AK-Freq</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>mni4</td>\n",
              "      <td>ꯂꯦꯡꯊꯩꯅꯕꯁꯤꯗꯤ</td>\n",
              "      <td>lengtheinabasidi</td>\n",
              "      <td>AK-Freq</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>mni5</td>\n",
              "      <td>ꯑꯦꯄ꯭ꯂꯥꯢꯗ</td>\n",
              "      <td>applied</td>\n",
              "      <td>AK-Freq</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10055</th>\n",
              "      <td>mni10056</td>\n",
              "      <td>ꯄꯥꯡꯒꯂ</td>\n",
              "      <td>panggala</td>\n",
              "      <td>IndicCorp</td>\n",
              "      <td>-0.174713</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10056</th>\n",
              "      <td>mni10057</td>\n",
              "      <td>ꯈꯣꯔꯤꯔꯣꯂꯒꯤ</td>\n",
              "      <td>khorirolagi</td>\n",
              "      <td>IndicCorp</td>\n",
              "      <td>-0.160257</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10057</th>\n",
              "      <td>mni10058</td>\n",
              "      <td>ꯃꯁꯤꯡꯈꯥ</td>\n",
              "      <td>masingkhaa</td>\n",
              "      <td>IndicCorp</td>\n",
              "      <td>-0.089934</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10058</th>\n",
              "      <td>mni10059</td>\n",
              "      <td>ꯄꯣꯛꯄꯥ</td>\n",
              "      <td>pokpaa</td>\n",
              "      <td>IndicCorp</td>\n",
              "      <td>-0.174966</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10059</th>\n",
              "      <td>mni10060</td>\n",
              "      <td>ꯁꯅꯥꯖꯥꯎꯕꯅ</td>\n",
              "      <td>sanajaobana</td>\n",
              "      <td>IndicCorp</td>\n",
              "      <td>-0.303592</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10060 rows × 5 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b7a5dac6-426e-4cd8-a4fe-291c4241819c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b7a5dac6-426e-4cd8-a4fe-291c4241819c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b7a5dac6-426e-4cd8-a4fe-291c4241819c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "      unique_identifier  native word      english word     source     score\n",
              "0                  mni1         ꯂꯨꯗꯨ              ludu    AK-Freq       NaN\n",
              "1                  mni2        ꯑꯣꯛꯁꯥ             oksha    AK-Freq       NaN\n",
              "2                  mni3        ꯊꯝꯕꯥꯜ           thambal    AK-Freq       NaN\n",
              "3                  mni4  ꯂꯦꯡꯊꯩꯅꯕꯁꯤꯗꯤ  lengtheinabasidi    AK-Freq       NaN\n",
              "4                  mni5     ꯑꯦꯄ꯭ꯂꯥꯢꯗ           applied    AK-Freq       NaN\n",
              "...                 ...          ...               ...        ...       ...\n",
              "10055          mni10056        ꯄꯥꯡꯒꯂ          panggala  IndicCorp -0.174713\n",
              "10056          mni10057    ꯈꯣꯔꯤꯔꯣꯂꯒꯤ       khorirolagi  IndicCorp -0.160257\n",
              "10057          mni10058       ꯃꯁꯤꯡꯈꯥ        masingkhaa  IndicCorp -0.089934\n",
              "10058          mni10059        ꯄꯣꯛꯄꯥ            pokpaa  IndicCorp -0.174966\n",
              "10059          mni10060     ꯁꯅꯥꯖꯥꯎꯕꯅ       sanajaobana  IndicCorp -0.303592\n",
              "\n",
              "[10060 rows x 5 columns]"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Read the CSV file using pandas\n",
        "train_data_frame = pd.read_json('/content/drive/MyDrive/Colab Notebooks/mni_train.json',lines=True)\n",
        "train_data_frame"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QCQHb-0OKIwN"
      },
      "source": [
        " the following code separates the 'native word' and 'english word' columns from the train_data_frame DataFrame and assigns them to mni_words and eng_words, respectively"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lPXjd_pJ-JZu",
        "outputId": "721fd9a8-4625-41ec-8734-3e87ca133ba7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0                    ludu\n",
              "1                   oksha\n",
              "2                 thambal\n",
              "3        lengtheinabasidi\n",
              "4                 applied\n",
              "               ...       \n",
              "10055            panggala\n",
              "10056         khorirolagi\n",
              "10057          masingkhaa\n",
              "10058              pokpaa\n",
              "10059         sanajaobana\n",
              "Name: english word, Length: 10060, dtype: object"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "features = train_data_frame.copy()\n",
        "mni_words = features.pop('native word')\n",
        "eng_words = features.pop('english word')\n",
        "eng_words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IK3o13b3-Yvp"
      },
      "outputs": [],
      "source": [
        "# Prepare the training data file\n",
        "#with open('/content/drive/MyDrive/Colab Notebooks/train_mni_Mtei.txt', 'a', encoding='utf-8') as f:\n",
        " #   for text in mni_words:\n",
        "  #      f.write(text + '\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yk9HX3VCAGcf"
      },
      "outputs": [],
      "source": [
        "manipuri_model = fasttext.train_unsupervised('/content/drive/MyDrive/Colab Notebooks/train_mni_Mtei.txt', minn=1, maxn=5, dim=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ieAHI7hPAxvf"
      },
      "outputs": [],
      "source": [
        "manipuri_model.save_model(\"/content/drive/MyDrive/Colab Notebooks/mm_word_min2_emb_trained.bin\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "a6tzfzz7BCcI",
        "outputId": "0ab70cb1-e7cb-4168-d21a-6043c1852e32"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([ 0.6619944 , -0.16315717, -0.30044603, -0.28545722, -0.5235201 ,\n",
              "       -0.15174791, -0.66545326,  0.15887249, -0.6327333 ,  0.13369572,\n",
              "       -0.6466927 ,  0.79841024, -0.40792543,  0.36684307, -0.78038985,\n",
              "       -0.36784878,  0.6376195 ,  1.0512756 , -0.90076894, -0.26770306,\n",
              "       -0.29650125,  0.581595  , -0.47365162,  0.21367358, -0.18608096,\n",
              "        0.0167257 ,  0.2632734 , -0.7259229 , -1.011928  , -0.05054175,\n",
              "        0.36914006, -0.66099715,  0.16792597, -0.35279256, -1.0820861 ,\n",
              "       -0.15252692, -0.58705634,  0.13675709, -0.5529628 , -0.25291088,\n",
              "       -0.00582439,  0.8513531 ,  0.08126765,  0.6232831 , -0.66333723,\n",
              "        0.30611265, -0.9358799 ,  0.74637824,  0.920117  , -0.6661053 ,\n",
              "       -0.29782978, -0.5366821 , -0.31153995,  0.11762436, -0.5079255 ,\n",
              "        0.20218125, -0.13303576, -0.97142977, -0.1973783 ,  0.15495472,\n",
              "        0.38155687,  0.211322  ,  1.3614364 ,  0.23373489,  0.472325  ,\n",
              "       -0.4221649 , -0.12420378, -0.05897048, -0.9241838 ,  0.23688698,\n",
              "        0.30837965,  1.4354686 ,  0.50586915, -0.14254878, -0.06198385,\n",
              "       -0.82922167, -0.07109694,  0.25854924,  0.392982  ,  0.39559358,\n",
              "       -0.04146577,  0.0920617 ,  1.5209064 , -0.47677097, -0.06731251,\n",
              "       -0.12771408,  1.2438604 ,  0.8362848 , -0.5015947 ,  0.27673456,\n",
              "       -0.46418047,  0.03736667,  0.36522838, -0.29195347, -0.16814077,\n",
              "       -1.2266288 ,  0.7637478 , -0.31608686, -0.20423041,  0.26092336],\n",
              "      dtype=float32)"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "manipuri_model.get_word_vector(\"ꯃ\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "k6uA1ffkfbef",
        "outputId": "b0fae688-fe04-489d-97bb-33bb7d197631"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "100"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "manipuri_model.get_dimension()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "dmf11mFiuPbN",
        "outputId": "dce6138e-bbb4-4780-b30a-e8d8d3d7897d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0                                l u d u\n",
            "1                              o k s h a\n",
            "2                          t h a m b a l\n",
            "3        l e n g t h e i n a b a s i d i\n",
            "4                          a p p l i e d\n",
            "                      ...               \n",
            "10055                    p a n g g a l a\n",
            "10056              k h o r i r o l a g i\n",
            "10057                m a s i n g k h a a\n",
            "10058                        p o k p a a\n",
            "10059              s a n a j a o b a n a\n",
            "Name: english word, Length: 10060, dtype: object\n",
            "0                      ꯂ ꯨ ꯗ ꯨ\n",
            "1                    ꯑ ꯣ ꯛ ꯁ ꯥ\n",
            "2                    ꯊ ꯝ ꯕ ꯥ ꯜ\n",
            "3        ꯂ ꯦ ꯡ ꯊ ꯩ ꯅ ꯕ ꯁ ꯤ ꯗ ꯤ\n",
            "4              ꯑ ꯦ ꯄ ꯭ ꯂ ꯥ ꯢ ꯗ\n",
            "                 ...          \n",
            "10055                ꯄ ꯥ ꯡ ꯒ ꯂ\n",
            "10056        ꯈ ꯣ ꯔ ꯤ ꯔ ꯣ ꯂ ꯒ ꯤ\n",
            "10057              ꯃ ꯁ ꯤ ꯡ ꯈ ꯥ\n",
            "10058                ꯄ ꯣ ꯛ ꯄ ꯥ\n",
            "10059          ꯁ ꯅ ꯥ ꯖ ꯥ ꯎ ꯕ ꯅ\n",
            "Name: native word, Length: 10060, dtype: object\n"
          ]
        }
      ],
      "source": [
        "# Function to split a word into characters\n",
        "def split_word_into_characters(word):\n",
        "    return ' '.join(list(word))\n",
        "\n",
        "# Apply character splitting to English dataframe\n",
        "eng_words = eng_words.apply(split_word_into_characters)\n",
        "\n",
        "# Apply character splitting to Manipuri dataframe\n",
        "mni_words = mni_words.apply(split_word_into_characters)\n",
        "\n",
        "# Print the updated dataframes\n",
        "print(eng_words)\n",
        "print(mni_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "cjL5VG0pwiC9"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FVlbe5hBMUM5"
      },
      "source": [
        "### Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "FUFxFWMRMdpw"
      },
      "outputs": [],
      "source": [
        "# Preprocess the input by removing spaces\n",
        "eng_words_preprocessed = [word.replace(' ', '') for word in eng_words]\n",
        "mni_words_preprocessed = [word.replace(' ', '') for word in mni_words]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "jSP0L-Jfu4mE"
      },
      "outputs": [],
      "source": [
        "# Initialize a tokenizer for English words with character-level tokenization\n",
        "eng_tokenizer = Tokenizer(char_level=True)\n",
        "eng_tokenizer.fit_on_texts(eng_words_preprocessed)\n",
        "\n",
        "# Convert the English words into sequences of integers using the fitted tokenizer\n",
        "eng_sequences = eng_tokenizer.texts_to_sequences(eng_words_preprocessed)\n",
        "\n",
        "mni_tokenizer = Tokenizer(char_level=True)\n",
        "mni_tokenizer.fit_on_texts(mni_words_preprocessed)\n",
        "mni_sequences = mni_tokenizer.texts_to_sequences(mni_words_preprocessed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "4OKgnD4Of2jm",
        "outputId": "a9cc9b29-ec70-442d-b89f-39426e264079"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "44"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(mni_tokenizer.word_index)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hPXAvm0wMX0B"
      },
      "source": [
        "### Padding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "5HG-O1c4wmHY",
        "outputId": "f2ee0bbf-6332-403d-9299-95f9a184fd3b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "22"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#calculates the maximum sequence length among all the sequences in both eng_sequences and mni_sequences.\n",
        "max_seq_length = max(max(len(seq) for seq in eng_sequences), max(len(seq) for seq in mni_sequences))\n",
        "eng_sequences_padded = pad_sequences(eng_sequences, maxlen=max_seq_length, padding='post')\n",
        "mni_sequences_padded = pad_sequences(mni_sequences, maxlen=max_seq_length, padding='post')\n",
        "max_seq_length"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "O50wItdVwykO",
        "outputId": "03d38486-94b0-4035-ca9e-1f29e7c90ac9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[12 10 17 ...  0  0  0]\n",
            " [ 9  6 13 ...  0  0  0]\n",
            " [ 8  4  1 ...  0  0  0]\n",
            " ...\n",
            " [ 7  1 13 ...  0  0  0]\n",
            " [14  9  6 ...  0  0  0]\n",
            " [13  1  3 ...  0  0  0]]\n",
            "[[ 9  6 11 ...  0  0  0]\n",
            " [27  8 19 ...  0  0  0]\n",
            " [23 17  5 ...  0  0  0]\n",
            " ...\n",
            " [13  4  1 ...  0  0  0]\n",
            " [14  8 19 ...  0  0  0]\n",
            " [ 4  3  2 ...  0  0  0]]\n"
          ]
        }
      ],
      "source": [
        "# Print the padded sequences\n",
        "print(eng_sequences_padded)\n",
        "print(mni_sequences_padded)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "1xrCTA7shPIs",
        "outputId": "4fe159e6-e4a4-499d-8803-172f5063f94f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([ 9,  6, 11,  6,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "        0,  0,  0,  0,  0], dtype=int32)"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "mni_sequences_padded[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yb_Vics6MJ3M"
      },
      "source": [
        "### Create word embeddings using FastText model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "lY8xC_q2zILM"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "eng_word_embeddings = np.zeros((len(eng_tokenizer.word_index) + 1, english_model.get_dimension()))\n",
        "mni_word_embeddings = np.zeros((len(mni_tokenizer.word_index) + 1, manipuri_model.get_dimension()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ObnbnhRvzebw"
      },
      "outputs": [],
      "source": [
        "for word, index in eng_tokenizer.word_index.items():\n",
        "    if word in english_model:\n",
        "        eng_word_embeddings[index] = english_model[word]\n",
        "\n",
        "for word, index in mni_tokenizer.word_index.items():\n",
        "    if word in manipuri_model:\n",
        "        mni_word_embeddings[index] = manipuri_model[word]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "XlPVW2Ocm0rD",
        "outputId": "99bfe6c7-bd41-4eae-a21a-1d57ec48eb98"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "dict_items([('ꯤ', 1), ('ꯥ', 2), ('ꯅ', 3), ('ꯁ', 4), ('ꯕ', 5), ('ꯨ', 6), ('ꯔ', 7), ('ꯣ', 8), ('ꯂ', 9), ('ꯡ', 10), ('ꯗ', 11), ('ꯟ', 12), ('ꯃ', 13), ('ꯄ', 14), ('ꯒ', 15), ('ꯦ', 16), ('ꯝ', 17), ('ꯇ', 18), ('ꯛ', 19), ('ꯀ', 20), ('ꯈ', 21), ('ꯌ', 22), ('ꯊ', 23), ('ꯍ', 24), ('ꯆ', 25), ('ꯩ', 26), ('ꯑ', 27), ('ꯐ', 28), ('ꯠ', 29), ('ꯜ', 30), ('ꯢ', 31), ('ꯧ', 32), ('ꯏ', 33), ('ꯖ', 34), ('ꯋ', 35), ('꯭', 36), ('ꯉ', 37), ('ꯎ', 38), ('ꯪ', 39), ('ꯞ', 40), ('ꯚ', 41), ('ꯓ', 42), ('ꯙ', 43), ('ꯘ', 44)])"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "mni_tokenizer.word_index.items()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J66ohaO55hld"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vHvRrb2mM3-D"
      },
      "source": [
        "### Define Encoder-Decoder Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "7nFqHNLKw1Ks"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, LSTM, Dense, Embedding, RepeatVector\n",
        "\n",
        "#encoder_input is defined as an input layer with a shape of (max_seq_length,), representing the input sequences.\n",
        "encoder_input = Input(shape=(max_seq_length,))\n",
        "#encoder_embedding is the embedding layer that takes the encoder_input as input.\n",
        "encoder_embedding = Embedding(len(eng_tokenizer.word_index) + 1, english_model.get_dimension(), weights=[eng_word_embeddings], trainable=False)(encoder_input)\n",
        "#encoder is an LSTM layer with 256 units that takes the embedded input sequences (encoder_embedding) as input and processes them to produce an encoded representation.\n",
        "encoder = LSTM(256)(encoder_embedding)\n",
        "\n",
        "#RepeatVector layer repeats the encoded representation max_seq_length times to align with the target sequence length.\n",
        "decoder = RepeatVector(max_seq_length)(encoder)\n",
        "#Another LSTM layer with 256 units is used as the decoder, taking the repeated encoded representation (decoder) as input and generating a sequence of outputs.\n",
        "#the RepeatVector layer serves as a way to provide the context vector to each time step of the decoder, as it repeats the context vector to align with the target sequence length.\n",
        "#The actual passing of hidden states between time steps is handled internally by the LSTM layer.\n",
        "decoder = LSTM(256, return_sequences=True)(decoder)\n",
        "#decoder_output is a Dense layer with the number of units equal to the size of the Mni vocabulary\n",
        "decoder_output = Dense(len(mni_tokenizer.word_index) + 1, activation='softmax')(decoder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "02gh46qc0GDE",
        "outputId": "99cc6a16-8bba-4d9a-b9ac-9a829553ac3d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 22)]              0         \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, 22, 300)           8100      \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 256)               570368    \n",
            "                                                                 \n",
            " repeat_vector (RepeatVector  (None, 22, 256)          0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 22, 256)           525312    \n",
            "                                                                 \n",
            " dense (Dense)               (None, 22, 45)            11565     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,115,345\n",
            "Trainable params: 1,107,245\n",
            "Non-trainable params: 8,100\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model = Model(inputs=encoder_input, outputs=decoder_output)\n",
        "\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "84JCHCAXzbg0",
        "outputId": "a1c0b5b1-4471-4802-d059-aab2e9305637"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "252/252 [==============================] - 17s 13ms/step - loss: 1.1274 - accuracy: 0.7239 - val_loss: 0.9555 - val_accuracy: 0.7509\n",
            "Epoch 2/100\n",
            "252/252 [==============================] - 2s 9ms/step - loss: 0.9753 - accuracy: 0.7410 - val_loss: 0.8763 - val_accuracy: 0.7600\n",
            "Epoch 3/100\n",
            "252/252 [==============================] - 2s 9ms/step - loss: 0.8456 - accuracy: 0.7610 - val_loss: 0.7460 - val_accuracy: 0.7873\n",
            "Epoch 4/100\n",
            "252/252 [==============================] - 2s 9ms/step - loss: 0.7153 - accuracy: 0.7875 - val_loss: 0.6306 - val_accuracy: 0.8159\n",
            "Epoch 5/100\n",
            "252/252 [==============================] - 3s 13ms/step - loss: 0.5774 - accuracy: 0.8263 - val_loss: 0.5456 - val_accuracy: 0.8369\n",
            "Epoch 6/100\n",
            "252/252 [==============================] - 2s 9ms/step - loss: 0.4674 - accuracy: 0.8575 - val_loss: 0.4646 - val_accuracy: 0.8615\n",
            "Epoch 7/100\n",
            "252/252 [==============================] - 2s 9ms/step - loss: 0.3744 - accuracy: 0.8860 - val_loss: 0.4927 - val_accuracy: 0.8488\n",
            "Epoch 8/100\n",
            "252/252 [==============================] - 2s 9ms/step - loss: 0.3181 - accuracy: 0.9024 - val_loss: 0.3967 - val_accuracy: 0.8779\n",
            "Epoch 9/100\n",
            "252/252 [==============================] - 2s 9ms/step - loss: 0.2604 - accuracy: 0.9204 - val_loss: 0.3496 - val_accuracy: 0.8946\n",
            "Epoch 10/100\n",
            "252/252 [==============================] - 3s 13ms/step - loss: 0.2169 - accuracy: 0.9344 - val_loss: 0.3492 - val_accuracy: 0.8952\n",
            "Epoch 11/100\n",
            "252/252 [==============================] - 2s 9ms/step - loss: 0.1843 - accuracy: 0.9445 - val_loss: 0.3375 - val_accuracy: 0.9002\n",
            "Epoch 12/100\n",
            "252/252 [==============================] - 2s 9ms/step - loss: 0.1554 - accuracy: 0.9539 - val_loss: 0.3240 - val_accuracy: 0.9051\n",
            "Epoch 13/100\n",
            "252/252 [==============================] - 2s 9ms/step - loss: 0.1374 - accuracy: 0.9588 - val_loss: 0.3173 - val_accuracy: 0.9087\n",
            "Epoch 14/100\n",
            "252/252 [==============================] - 2s 10ms/step - loss: 0.1172 - accuracy: 0.9655 - val_loss: 0.3275 - val_accuracy: 0.9059\n",
            "Epoch 15/100\n",
            "252/252 [==============================] - 3s 13ms/step - loss: 0.1009 - accuracy: 0.9708 - val_loss: 0.3199 - val_accuracy: 0.9087\n",
            "Epoch 16/100\n",
            "252/252 [==============================] - 2s 10ms/step - loss: 0.0885 - accuracy: 0.9747 - val_loss: 0.3135 - val_accuracy: 0.9125\n",
            "Epoch 17/100\n",
            "252/252 [==============================] - 2s 9ms/step - loss: 0.0780 - accuracy: 0.9780 - val_loss: 0.3354 - val_accuracy: 0.9139\n",
            "Epoch 18/100\n",
            "252/252 [==============================] - 2s 9ms/step - loss: 0.0811 - accuracy: 0.9761 - val_loss: 0.3322 - val_accuracy: 0.9116\n",
            "Epoch 19/100\n",
            "252/252 [==============================] - 2s 10ms/step - loss: 0.0676 - accuracy: 0.9807 - val_loss: 0.3307 - val_accuracy: 0.9127\n",
            "Epoch 20/100\n",
            "252/252 [==============================] - 3s 12ms/step - loss: 0.0671 - accuracy: 0.9806 - val_loss: 0.3382 - val_accuracy: 0.9145\n",
            "Epoch 21/100\n",
            "252/252 [==============================] - 3s 10ms/step - loss: 0.0502 - accuracy: 0.9861 - val_loss: 0.3259 - val_accuracy: 0.9193\n",
            "Epoch 22/100\n",
            "252/252 [==============================] - 2s 9ms/step - loss: 0.0456 - accuracy: 0.9878 - val_loss: 0.3412 - val_accuracy: 0.9136\n",
            "Epoch 23/100\n",
            "252/252 [==============================] - 2s 9ms/step - loss: 0.0429 - accuracy: 0.9881 - val_loss: 0.3310 - val_accuracy: 0.9184\n",
            "Epoch 24/100\n",
            "252/252 [==============================] - 2s 9ms/step - loss: 0.0310 - accuracy: 0.9921 - val_loss: 0.3451 - val_accuracy: 0.9181\n",
            "Epoch 25/100\n",
            "252/252 [==============================] - 3s 12ms/step - loss: 0.0293 - accuracy: 0.9925 - val_loss: 0.3459 - val_accuracy: 0.9189\n",
            "Epoch 26/100\n",
            "252/252 [==============================] - 2s 10ms/step - loss: 0.0321 - accuracy: 0.9917 - val_loss: 0.3434 - val_accuracy: 0.9219\n",
            "Epoch 27/100\n",
            "252/252 [==============================] - 2s 9ms/step - loss: 0.0535 - accuracy: 0.9838 - val_loss: 0.3796 - val_accuracy: 0.9116\n",
            "Epoch 28/100\n",
            "252/252 [==============================] - 2s 9ms/step - loss: 0.0442 - accuracy: 0.9867 - val_loss: 0.3676 - val_accuracy: 0.9156\n",
            "Epoch 29/100\n",
            "252/252 [==============================] - 2s 9ms/step - loss: 0.0298 - accuracy: 0.9920 - val_loss: 0.3608 - val_accuracy: 0.9214\n",
            "Epoch 30/100\n",
            "252/252 [==============================] - 3s 12ms/step - loss: 0.0231 - accuracy: 0.9941 - val_loss: 0.3761 - val_accuracy: 0.9214\n",
            "Epoch 31/100\n",
            "252/252 [==============================] - 3s 10ms/step - loss: 0.0214 - accuracy: 0.9942 - val_loss: 0.3709 - val_accuracy: 0.9202\n",
            "Epoch 32/100\n",
            "252/252 [==============================] - 2s 9ms/step - loss: 0.0290 - accuracy: 0.9919 - val_loss: 0.3703 - val_accuracy: 0.9209\n",
            "Epoch 33/100\n",
            "252/252 [==============================] - 2s 9ms/step - loss: 0.0265 - accuracy: 0.9928 - val_loss: 0.3833 - val_accuracy: 0.9186\n",
            "Epoch 34/100\n",
            "252/252 [==============================] - 2s 9ms/step - loss: 0.0422 - accuracy: 0.9873 - val_loss: 0.3720 - val_accuracy: 0.9224\n",
            "Epoch 35/100\n",
            "252/252 [==============================] - 3s 11ms/step - loss: 0.0342 - accuracy: 0.9899 - val_loss: 0.3630 - val_accuracy: 0.9208\n",
            "Epoch 36/100\n",
            "252/252 [==============================] - 3s 10ms/step - loss: 0.0247 - accuracy: 0.9931 - val_loss: 0.3777 - val_accuracy: 0.9224\n",
            "Epoch 37/100\n",
            "252/252 [==============================] - 2s 9ms/step - loss: 0.0155 - accuracy: 0.9958 - val_loss: 0.3889 - val_accuracy: 0.9218\n",
            "Epoch 38/100\n",
            "252/252 [==============================] - 2s 9ms/step - loss: 0.0112 - accuracy: 0.9970 - val_loss: 0.3794 - val_accuracy: 0.9233\n",
            "Epoch 39/100\n",
            "252/252 [==============================] - 2s 9ms/step - loss: 0.0108 - accuracy: 0.9969 - val_loss: 0.3913 - val_accuracy: 0.9262\n",
            "Epoch 40/100\n",
            "252/252 [==============================] - 3s 11ms/step - loss: 0.0330 - accuracy: 0.9899 - val_loss: 0.4206 - val_accuracy: 0.9116\n",
            "Epoch 41/100\n",
            "252/252 [==============================] - 3s 11ms/step - loss: 0.0496 - accuracy: 0.9841 - val_loss: 0.4221 - val_accuracy: 0.9151\n",
            "Epoch 42/100\n",
            "252/252 [==============================] - 2s 9ms/step - loss: 0.0303 - accuracy: 0.9909 - val_loss: 0.3799 - val_accuracy: 0.9213\n",
            "Epoch 43/100\n",
            "252/252 [==============================] - 2s 9ms/step - loss: 0.0142 - accuracy: 0.9960 - val_loss: 0.3777 - val_accuracy: 0.9254\n",
            "Epoch 44/100\n",
            "252/252 [==============================] - 2s 9ms/step - loss: 0.0102 - accuracy: 0.9969 - val_loss: 0.3844 - val_accuracy: 0.9265\n",
            "Epoch 45/100\n",
            "252/252 [==============================] - 2s 9ms/step - loss: 0.0091 - accuracy: 0.9971 - val_loss: 0.3876 - val_accuracy: 0.9273\n",
            "Epoch 46/100\n",
            "252/252 [==============================] - 3s 12ms/step - loss: 0.0086 - accuracy: 0.9972 - val_loss: 0.3991 - val_accuracy: 0.9265\n",
            "Epoch 47/100\n",
            "252/252 [==============================] - 2s 9ms/step - loss: 0.0086 - accuracy: 0.9972 - val_loss: 0.4031 - val_accuracy: 0.9233\n",
            "Epoch 48/100\n",
            "252/252 [==============================] - 2s 9ms/step - loss: 0.0085 - accuracy: 0.9972 - val_loss: 0.3977 - val_accuracy: 0.9264\n",
            "Epoch 49/100\n",
            "252/252 [==============================] - 2s 9ms/step - loss: 0.0114 - accuracy: 0.9966 - val_loss: 0.4041 - val_accuracy: 0.9223\n",
            "Epoch 50/100\n",
            "252/252 [==============================] - 2s 9ms/step - loss: 0.0462 - accuracy: 0.9855 - val_loss: 0.5011 - val_accuracy: 0.9032\n",
            "Epoch 51/100\n",
            "252/252 [==============================] - 3s 12ms/step - loss: 0.0594 - accuracy: 0.9809 - val_loss: 0.4019 - val_accuracy: 0.9191\n",
            "Epoch 52/100\n",
            "252/252 [==============================] - 2s 10ms/step - loss: 0.0162 - accuracy: 0.9952 - val_loss: 0.3905 - val_accuracy: 0.9239\n",
            "Epoch 53/100\n",
            "252/252 [==============================] - 2s 9ms/step - loss: 0.0094 - accuracy: 0.9973 - val_loss: 0.3837 - val_accuracy: 0.9260\n",
            "Epoch 54/100\n",
            "252/252 [==============================] - 2s 9ms/step - loss: 0.0088 - accuracy: 0.9971 - val_loss: 0.3946 - val_accuracy: 0.9247\n",
            "Epoch 55/100\n",
            "252/252 [==============================] - 2s 9ms/step - loss: 0.0072 - accuracy: 0.9975 - val_loss: 0.3966 - val_accuracy: 0.9269\n",
            "Epoch 56/100\n",
            "252/252 [==============================] - 3s 10ms/step - loss: 0.0074 - accuracy: 0.9974 - val_loss: 0.4000 - val_accuracy: 0.9278\n",
            "Epoch 57/100\n",
            "252/252 [==============================] - 3s 11ms/step - loss: 0.0075 - accuracy: 0.9975 - val_loss: 0.4000 - val_accuracy: 0.9270\n",
            "Epoch 58/100\n",
            "252/252 [==============================] - 2s 9ms/step - loss: 0.0072 - accuracy: 0.9973 - val_loss: 0.3975 - val_accuracy: 0.9279\n",
            "Epoch 59/100\n",
            "252/252 [==============================] - 2s 9ms/step - loss: 0.0072 - accuracy: 0.9974 - val_loss: 0.4078 - val_accuracy: 0.9271\n",
            "Epoch 60/100\n",
            "252/252 [==============================] - 2s 9ms/step - loss: 0.0101 - accuracy: 0.9968 - val_loss: 0.4447 - val_accuracy: 0.9205\n",
            "Epoch 61/100\n",
            "252/252 [==============================] - 2s 9ms/step - loss: 0.0736 - accuracy: 0.9768 - val_loss: 0.4044 - val_accuracy: 0.9146\n",
            "Epoch 62/100\n",
            "252/252 [==============================] - 3s 13ms/step - loss: 0.0331 - accuracy: 0.9891 - val_loss: 0.4060 - val_accuracy: 0.9215\n",
            "Epoch 63/100\n",
            "252/252 [==============================] - 2s 9ms/step - loss: 0.0129 - accuracy: 0.9959 - val_loss: 0.4045 - val_accuracy: 0.9248\n",
            "Epoch 64/100\n",
            "252/252 [==============================] - 2s 9ms/step - loss: 0.0095 - accuracy: 0.9969 - val_loss: 0.3895 - val_accuracy: 0.9271\n",
            "Epoch 65/100\n",
            "252/252 [==============================] - 2s 9ms/step - loss: 0.0065 - accuracy: 0.9975 - val_loss: 0.3932 - val_accuracy: 0.9294\n",
            "Epoch 66/100\n",
            "252/252 [==============================] - 2s 9ms/step - loss: 0.0057 - accuracy: 0.9977 - val_loss: 0.4031 - val_accuracy: 0.9283\n",
            "Epoch 67/100\n",
            "252/252 [==============================] - 3s 12ms/step - loss: 0.0056 - accuracy: 0.9977 - val_loss: 0.4001 - val_accuracy: 0.9293\n",
            "Epoch 68/100\n",
            "252/252 [==============================] - 2s 9ms/step - loss: 0.0056 - accuracy: 0.9976 - val_loss: 0.4046 - val_accuracy: 0.9293\n",
            "Epoch 69/100\n",
            "252/252 [==============================] - 2s 9ms/step - loss: 0.0062 - accuracy: 0.9977 - val_loss: 0.4145 - val_accuracy: 0.9275\n",
            "Epoch 70/100\n",
            "252/252 [==============================] - 2s 9ms/step - loss: 0.0071 - accuracy: 0.9974 - val_loss: 0.4267 - val_accuracy: 0.9257\n",
            "Epoch 71/100\n",
            "252/252 [==============================] - 2s 9ms/step - loss: 0.0332 - accuracy: 0.9898 - val_loss: 0.4825 - val_accuracy: 0.9048\n",
            "Epoch 72/100\n",
            "252/252 [==============================] - 3s 11ms/step - loss: 0.0502 - accuracy: 0.9839 - val_loss: 0.4237 - val_accuracy: 0.9184\n",
            "Epoch 73/100\n",
            "252/252 [==============================] - 2s 10ms/step - loss: 0.0214 - accuracy: 0.9933 - val_loss: 0.4109 - val_accuracy: 0.9234\n",
            "Epoch 74/100\n",
            "252/252 [==============================] - 2s 9ms/step - loss: 0.0112 - accuracy: 0.9964 - val_loss: 0.4083 - val_accuracy: 0.9248\n",
            "Epoch 75/100\n",
            "252/252 [==============================] - 2s 9ms/step - loss: 0.0077 - accuracy: 0.9973 - val_loss: 0.4052 - val_accuracy: 0.9257\n",
            "Epoch 76/100\n",
            "252/252 [==============================] - 2s 9ms/step - loss: 0.0065 - accuracy: 0.9974 - val_loss: 0.4070 - val_accuracy: 0.9268\n",
            "Epoch 77/100\n",
            "252/252 [==============================] - 3s 10ms/step - loss: 0.0060 - accuracy: 0.9975 - val_loss: 0.4127 - val_accuracy: 0.9278\n",
            "Epoch 78/100\n",
            "252/252 [==============================] - 3s 11ms/step - loss: 0.0057 - accuracy: 0.9977 - val_loss: 0.4197 - val_accuracy: 0.9275\n",
            "Epoch 79/100\n",
            "252/252 [==============================] - 2s 9ms/step - loss: 0.0060 - accuracy: 0.9975 - val_loss: 0.4331 - val_accuracy: 0.9242\n",
            "Epoch 80/100\n",
            "252/252 [==============================] - 2s 9ms/step - loss: 0.0097 - accuracy: 0.9968 - val_loss: 0.4295 - val_accuracy: 0.9227\n",
            "Epoch 81/100\n",
            "252/252 [==============================] - 2s 9ms/step - loss: 0.0447 - accuracy: 0.9861 - val_loss: 0.4469 - val_accuracy: 0.9139\n",
            "Epoch 82/100\n",
            "252/252 [==============================] - 2s 9ms/step - loss: 0.0329 - accuracy: 0.9894 - val_loss: 0.4365 - val_accuracy: 0.9196\n",
            "Epoch 83/100\n",
            "252/252 [==============================] - 3s 12ms/step - loss: 0.0141 - accuracy: 0.9956 - val_loss: 0.4229 - val_accuracy: 0.9236\n",
            "Epoch 84/100\n",
            "252/252 [==============================] - 2s 9ms/step - loss: 0.0080 - accuracy: 0.9972 - val_loss: 0.4172 - val_accuracy: 0.9267\n",
            "Epoch 85/100\n",
            "252/252 [==============================] - 2s 9ms/step - loss: 0.0062 - accuracy: 0.9975 - val_loss: 0.4234 - val_accuracy: 0.9262\n",
            "Epoch 86/100\n",
            "252/252 [==============================] - 2s 9ms/step - loss: 0.0057 - accuracy: 0.9975 - val_loss: 0.4289 - val_accuracy: 0.9270\n",
            "Epoch 87/100\n",
            "252/252 [==============================] - 2s 9ms/step - loss: 0.0053 - accuracy: 0.9976 - val_loss: 0.4262 - val_accuracy: 0.9273\n",
            "Epoch 88/100\n",
            "252/252 [==============================] - 3s 12ms/step - loss: 0.0052 - accuracy: 0.9976 - val_loss: 0.4276 - val_accuracy: 0.9267\n",
            "Epoch 89/100\n",
            "252/252 [==============================] - 3s 10ms/step - loss: 0.0051 - accuracy: 0.9977 - val_loss: 0.4260 - val_accuracy: 0.9275\n",
            "Epoch 90/100\n",
            "252/252 [==============================] - 2s 9ms/step - loss: 0.0052 - accuracy: 0.9975 - val_loss: 0.4254 - val_accuracy: 0.9275\n",
            "Epoch 91/100\n",
            "252/252 [==============================] - 2s 9ms/step - loss: 0.0055 - accuracy: 0.9976 - val_loss: 0.4319 - val_accuracy: 0.9265\n",
            "Epoch 92/100\n",
            "252/252 [==============================] - 2s 9ms/step - loss: 0.0242 - accuracy: 0.9921 - val_loss: 0.4977 - val_accuracy: 0.9077\n",
            "Epoch 93/100\n",
            "252/252 [==============================] - 3s 10ms/step - loss: 0.0603 - accuracy: 0.9809 - val_loss: 0.4548 - val_accuracy: 0.9155\n",
            "Epoch 94/100\n",
            "252/252 [==============================] - 3s 11ms/step - loss: 0.0245 - accuracy: 0.9921 - val_loss: 0.4141 - val_accuracy: 0.9228\n",
            "Epoch 95/100\n",
            "252/252 [==============================] - 2s 9ms/step - loss: 0.0098 - accuracy: 0.9967 - val_loss: 0.4252 - val_accuracy: 0.9254\n",
            "Epoch 96/100\n",
            "252/252 [==============================] - 2s 9ms/step - loss: 0.0066 - accuracy: 0.9973 - val_loss: 0.4175 - val_accuracy: 0.9268\n",
            "Epoch 97/100\n",
            "252/252 [==============================] - 2s 9ms/step - loss: 0.0052 - accuracy: 0.9976 - val_loss: 0.4283 - val_accuracy: 0.9281\n",
            "Epoch 98/100\n",
            "252/252 [==============================] - 2s 9ms/step - loss: 0.0049 - accuracy: 0.9976 - val_loss: 0.4223 - val_accuracy: 0.9293\n",
            "Epoch 99/100\n",
            "252/252 [==============================] - 3s 13ms/step - loss: 0.0048 - accuracy: 0.9976 - val_loss: 0.4224 - val_accuracy: 0.9276\n",
            "Epoch 100/100\n",
            "252/252 [==============================] - 2s 9ms/step - loss: 0.0048 - accuracy: 0.9977 - val_loss: 0.4290 - val_accuracy: 0.9287\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f7e9c5bc7f0>"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Model Training\n",
        "model.fit(eng_sequences_padded, mni_sequences_padded, epochs=150, validation_split=0.2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "PgqFu5XSyor1",
        "outputId": "b2757767-9746-4c74-e312-4f91bf96ef39"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
          ]
        }
      ],
      "source": [
        "model.save(\"/content/drive/MyDrive/Colab Notebooks/machinelstmmodelreal.bin\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RxSBaFmqSv5o"
      },
      "source": [
        "###Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "VW0QV5lRafUQ"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "model = tf.keras.models.load_model(\"/content/drive/MyDrive/Colab Notebooks/machinelstmmodelreal.bin\")\n",
        "# Read the test CSV file using pandas\n",
        "test_data_frame = pd.read_json('/content/drive/MyDrive/Colab Notebooks/mni_test.json', lines=True)\n",
        "\n",
        "# Copy the dataframe\n",
        "test_features = test_data_frame.copy()\n",
        "\n",
        "\n",
        "\n",
        "# Pop 'native word' and 'english word' columns from the test dataframe\n",
        "test_mni_words = test_features.pop('native word')\n",
        "test_eng_words = test_features.pop('english word')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GLt_Y5EB8dXn"
      },
      "outputs": [],
      "source": [
        "# Apply character splitting to English test dataframe\n",
        "test_eng_words = test_eng_words.apply(split_word_into_characters)\n",
        "\n",
        "# Apply character splitting to Manipuri test dataframe\n",
        "test_mni_words = test_mni_words.apply(split_word_into_characters)\n",
        "\n",
        "# Tokenization of test data\n",
        "test_eng_sequences = eng_tokenizer.texts_to_sequences(test_eng_words)\n",
        "test_mni_sequences = mni_tokenizer.texts_to_sequences(test_mni_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "z1PY-djj8g5j"
      },
      "outputs": [],
      "source": [
        "# Padding of test sequences\n",
        "test_eng_sequences_padded = pad_sequences(test_eng_sequences, maxlen=max_seq_length, padding='post')\n",
        "test_mni_sequences_padded = pad_sequences(test_mni_sequences, maxlen=max_seq_length, padding='post')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tQZ9csSA8nN2",
        "outputId": "7ed830b8-918e-488d-b332-b79f014c3e79"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "153/153 [==============================] - 2s 9ms/step - loss: 0.7507 - accuracy: 0.8889\n",
            "88.88506889343262\n"
          ]
        }
      ],
      "source": [
        "# Model Evaluation\n",
        "evaluation = model.evaluate( test_eng_sequences_padded,test_mni_sequences_padded)\n",
        "print(evaluation[1]*100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3yNikaC3zQH4",
        "outputId": "658a71ca-094f-4ca5-b58b-1f27af17f884"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "153/153 [==============================] - 2s 7ms/step\n",
            "BLEU score: 0.4979800119575156\n",
            "Average CER: 0.3081052438845445\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.translate.bleu_score import corpus_bleu\n",
        "\n",
        "# Generate predictions using the trained model\n",
        "predictions = model.predict(test_eng_sequences_padded)\n",
        "\n",
        "# Convert predictions to text\n",
        "predicted_sentences = []\n",
        "for prediction in predictions:\n",
        "    sentence = \"\"\n",
        "    for index in np.argmax(prediction, axis=1):\n",
        "        if index != 0:\n",
        "            word = mni_tokenizer.index_word[index]\n",
        "            sentence += word\n",
        "    predicted_sentences.append(sentence)\n",
        "\n",
        "# Convert ground truth Manipuri sentences to a list of lists\n",
        "reference_sentences = [list(sentence) for sentence in test_mni_words]\n",
        "\n",
        "\n",
        "#Reshaping the reference sentence and predicted sentences\n",
        "reference_sentences  = [[char for char in sublist if char != ' '] for sublist in reference_sentences]\n",
        "predicted_sentences= [list(string) for string in predicted_sentences]\n",
        "\n",
        "# Compute BLEU score\n",
        "bleu_score = corpus_bleu([[sentence] for sentence in reference_sentences], predicted_sentences)\n",
        "\n",
        "print(\"BLEU score:\", bleu_score)\n",
        "\n",
        "\n",
        "# Function to calculate Character Error Rate (CER)\n",
        "def character_error_rate(true, pred):\n",
        "    dist = nltk.edit_distance(true, pred)\n",
        "    return dist / len(true)\n",
        "\n",
        "\n",
        "# Calculate CER for each predicted sentence\n",
        "cer_scores = []\n",
        "for true, pred in zip(reference_sentences, predicted_sentences):\n",
        "    cer = character_error_rate(true, list(pred))\n",
        "    cer_scores.append(cer)\n",
        "\n",
        "average_cer = sum(cer_scores) / len(cer_scores)\n",
        "print(\"Average CER:\", average_cer)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KIGo5EOTandQ",
        "outputId": "f930fa28-4d33-40da-c1a4-85cafad7ba64"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['ꯌ', 'ꯥ', 'ꯜ', 'ꯂ', 'ꯒ']\n",
            "['ꯌ', 'ꯥ', 'ꯜ', 'ꯂ', 'ꯒ']\n"
          ]
        }
      ],
      "source": [
        "print(reference_sentences[0])\n",
        "print(predicted_sentences[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V2WHnQcJ9Q2B",
        "outputId": "99f92e4e-ea8e-472c-d00b-813d932309b2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter an English word: eigi\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "Input: eigi\n",
            "Predicted Transliteration: ꯏꯩꯒꯤ\n"
          ]
        }
      ],
      "source": [
        "# Function to predict transliteration\n",
        "def predict_transliteration(input_word):\n",
        "    # Preprocess input word\n",
        "    input_word = split_word_into_characters(input_word)\n",
        "    input_sequence = eng_tokenizer.texts_to_sequences([input_word])\n",
        "    input_sequence_padded = pad_sequences(input_sequence, maxlen=max_seq_length, padding='post')\n",
        "\n",
        "    # Perform prediction\n",
        "    predicted_sequence = model.predict(input_sequence_padded)\n",
        "\n",
        "    # Convert predicted sequence to text\n",
        "    predicted_word = ''\n",
        "    for seq in predicted_sequence[0]:\n",
        "        index = np.argmax(seq)\n",
        "        if index in mni_tokenizer.index_word:\n",
        "            predicted_char = mni_tokenizer.index_word[index]\n",
        "            if predicted_char != ' ':\n",
        "                predicted_word += predicted_char\n",
        "        else:\n",
        "            predicted_word += ''\n",
        "\n",
        "    return predicted_word\n",
        "\n",
        "# Get user input for the input word\n",
        "input_word = input(\"Enter an English word: \")\n",
        "\n",
        "# Predict transliteration\n",
        "predicted_transliteration = predict_transliteration(input_word)\n",
        "\n",
        "# Print the results\n",
        "print('Input:', input_word)\n",
        "print('Predicted Transliteration:', predicted_transliteration)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}